def find_neighbors(E,ell):
    """
    Computes the isosogenies whose kernels are the ell+1 nonzero cyclic subgroups of E[ell].

    The output is a dictionary, whose keys are the neighbor j-invariants and the value of j' is a
    list of isogenies between E and E(j').
    """

    F = E.base_field()
    if ell == 2:
        R.<x> = F['x']
        f = x^3 + F(E.a_invariants()[3])*x + F(E.a_invariants()[4])
        kernel_polys = [factor[0] for factor in f.factor()]
    else:
        factors = E.division_polynomial(ell).factor()
        kernel_polys = []
        for factor in factors:
            if factor[0].degree() == (ell-1)/2:
                kernel_polys.append(factor[0])
            else:
                for f in kernel_polys:
                    if factor[0].divides(f):
                        continue
                K.<b> = factor[0].splitting_field()
                L.<c> = K.extension(2)
                R.<x> = K['x']
                G = R(factor[0])
                new_factors = G.factor()
                xP = -new_factors[0][0][0]
                E = E.change_ring(L)
                yP = find_y_coordinate(E,xP)
                P = E(xP,yP)
                kernel_poly = (x-xP)
                for k in range(2,ell):
                    P = P + P
                    xP = P[0]
                    if kernel_poly(xP) == 0:
                        continue
                    else:
                        kernel_poly = kernel_poly*(x-xP)
                kernel_polys.append(kernel_poly)
    edges = {}
    E = E.change_ring(F)
    for kernel_poly in kernel_polys:
        phi = EllipticCurveIsogeny(E,kernel_poly)
        phiE = phi.codomain()
        j = phiE.j_invariant()
        if j in edges:
            multiple_edges = edges[j]
            multiple_edges.append(phi)
            edges[j] = multiple_edges
        else:
            edges[j] = [phi]
    return edges



def evaluate_chain(chain,P):
    """
    Evaluates the isogeny chain at a point P.
    """

    Q = P
    for phi in chain:
        Q = phi(Q)
    return Q

# Functions for computing the trace of an endomorphism represented by a sequence of ell-isogenies.
# The code here is adapted from functions for computing the trace of Frobenius, by Sutherland,
# available at https://math.mit.edu/classes/18.783/2019/lectures.html


# The elliptic curve E is in Weierstrass form y^2=f(x)=x^3+Ax+B

divpoly_factor = 0    # global variable for factor of the division polynomial when ZeroDivisionError's occur

# Elements of End(E[ell]) are represented as pairs (a,b*y), with a,b in Fp[x]/(h(x)), where h is the ell-th divpoly (or a factor of it, for example, the kernel polynomial of an isogeny)
# The y is implicit, but must be accounted for when applying the group law -- using the curve equation y^2=f(x) we can replace y^2 with f(x) whenever it appears (this effectively hides all the y's)

# In many of the functions below we pass in both A and f
# where f is the image of x^3+Ax+B in Fp[x]/(h(x)) -- we need both because if deg(h)<= 3 we cannot recover A from (x^3+Ax+B) mod h(x)

def add(P,Q,A,f):
    """add endomorphisms P and Q in End(E[ell])"""
    global divpoly_factor
    if not P: return Q
    if not Q: return P
    a1 = P[0]; b1 = P[1]; a2=Q[0]; b2=Q[1]
    if a1 == a2:
        if b1 == b2: return dbl(P,A,f)
        else: return ()
    try:
        m = (b2-b1)/(a2-a1)
    except ZeroDivisionError:
        ### given that a2-a1 is already reduced mod h, a ZeroDivisionError means that gcd(a2-a1,h) must be a nontrivial divisor g of h
        ### raise an error so that we can restart the algorithm working in a smaller quotient ring
        divpoly_factor = a2-a1
        raise
    a3 = f*m^2 -a1 - a2
    b3 = m*(a1-a3) - b1
    return (a3,b3)

def dbl(P,A,f):
    """double the endomorphism P in End(E[ell]) """
    global divpoly_factor
    if not P: return P
    a1 = P[0]; b1 = P[1]
    try:
        m = (3*a1^2+A) / (2*b1*f)
    except ZeroDivisionError:
        divpoly_factor = 2*b1*f
        raise
    a3 = f*m^2 - 2*a1
    b3 = m*(a1-a3) - b1
    return (a3,b3)

def neg(P):
    """ negate the endomorphism P in End(E[ell]) """
    if not P: return P
    return (P[0],-P[1])

def smul (n,P,A,f):
    """ compute the scalar multiple n*P in End(E[ell]) using double and add"""
    if not n: return ()
    nbits = n.digits(2)
    i = len(nbits)-2
    Q = P
    while i >= 0:
        Q = dbl(Q,A,f)
        if nbits[i]: Q = add(P,Q,A,f)
        i -= 1
    return Q

def mul (P,Q):
    """ compute the product (i.e. composition of) P*Q of two endomorphisms in End(E[ell]) """
    return (P[0].lift()(Q[0]),P[1].lift()(Q[0])*Q[1])



def compose_and_reduce_chain(chain, h):
    E = chain[0].domain()
    FF = E.base_ring()
    R.<x> = PolynomialRing(FF)
    RR.<xbar> = R.quotient(ideal(h))
    phi0 = chain[0]
    a, b = phi0.rational_maps()
    a0 = a.numerator()
    a1 = a.denominator()
    b0 = b.numerator()(y=1)
    b1 = b.denominator()
    a = RR(a0) * RR(a1)**(-1)
    b = RR(b0) * RR(b1)**(-1)
    for k in range(1, len(chain)):
        phi = chain[k]
        phix, phiy = phi.rational_maps()
        a_prev = a.lift()
        b_prev = b.lift()
        U = RR(phix.numerator()(x = a_prev))
        V = RR(phix.denominator()(x = a_prev))
        S = RR(phiy.numerator()(x = a_prev, y = b_prev))
        T = RR(phiy.denominator()(x = a_prev))
        phix = U * (V**(-1))
        phiy = S * (T**(-1))
        a = phix
        b = phiy
    return (a, b)

def trace_of_endo_mod(endo, M):
    """Computes the trace of endo mod M """
    E = endo[0].domain()
    FF=E.base_ring()
    ell = endo[0].degree()                       # deg(endo) = ell^(len(endo))
    deg = ell^(len(endo))
    R.<x>=PolynomialRing(FF)
    A=E.a4(); B=E.a6()                          # E: y^2 = x^3 + Ax + B
    h = E.division_polynomial(M, x, 0).monic()
    while true:
        try:
            RR.<xbar> = R.quotient(ideal(h))       # RR is End(E[ell]) (or a subring thereof)
            f = xbar^3+A*xbar+B
            alpha = compose_and_reduce_chain(endo, h)
            alpha2 = mul(alpha, alpha)          # alpha2 = alpha^2
            identity = (xbar,RR(1))             # identity aka mult-by-1 map
            Q = smul(deg%M, identity, A, f)     # Q is the mult-by-deg map
            S = add(alpha2, Q, A, f)            # S = alpha^2 + deg = t*alpha
            if not S: return 0                  # if S=0 then t=0
            if S == alpha: return 1             # if S=alpha then t=1
            if neg(S) == alpha: return -1       # if S=-alpha then t=-1
            P = alpha
            for t in range(2,M-1):
                P = add(P, alpha, A, f)         # P = t*pi
                if P == S: return t             # if S=P then we have found t
            print("Error, endo satisfies no charpoly!!")
            assert false
        except ZeroDivisionError:
            h = gcd(h,divpoly_factor.lift())    # if we hit a zero divisor, start over with new h
#             print("found %d-divpoly factor of degree %d"%(M,h.degree()))


def generalized_Schoof(endo):
    """ compute the trace of endo using generalized Schoof's algorithm """
    ell = endo[0].degree()
    degree = ell**(len(endo))
    t = 0; N = 1; M = 2;
    while N <= 4*sqrt(degree):
        M = next_prime(M)
        if M == ell:
            M = next_prime(M)
        start = cputime()
        tM = trace_of_endo_mod(endo, M)
#         print("trace %d mod %d computed in %.2f secs"%(tM, M, cputime()-start))
        a = N * N.inverse_mod(M); b = M * M.inverse_mod(N)
        N *= M
        t = (a*tM + b*t) % N
    if t >= N/2: return t-N
    else: return t


# Functions for navigating isogeny graphs and finding cycles.
def adjacent_vertices(j, ell):
    '''
    Returns the j-invariants adjacent to j in the ell-isogeny graph.
    '''
    F = j.parent()
    p = F.characteristic()
    phi_ell = ClassicalModularPolynomialDatabase()[ell];
    FX.<X> = PolynomialRing(F)
    FXY.<X, Y> = PolynomialRing(F)
    phi_ell = FXY(phi_ell)
    phi_ell_j = FX(phi_ell(Y = j))
    neighbors = [root[0] for root in phi_ell_j.roots()]
    return neighbors

def random_walk(j0, ell):
    F = j0.parent()
    p = F.characteristic()
    length = floor(log(p, 2))
    path = [j0]
    for k in range(length):
        jk = path[k]
        neighbors = adjacent_vertices(jk, ell)
        idx = randint(0, len(neighbors) - 1)
        path.append(neighbors[idx])
    return path

def random_walks_to_Fp(j0, ell):
    F = j0.parent()
    p = F.characteristic()
    Fp = F.base_ring()
    length = floor(log(p, 2))
    while True:
        path = [j0]
        for k in range(length):
            jk = path[k]
            neighbors = adjacent_vertices(jk, ell)
            idx = randint(0, len(neighbors) - 1)
            j = neighbors[idx]
            path.append(j)
            if j in Fp:
                return path

def trim(path):
    '''Removes all loops and backtracking from path.'''
    if len(path) <= 1:
        return path
    elif len(path) == 2:
        if path[0] != path[1]:
            return path
        else:
            return [path[0]]
    else:
        trimmed = [path[0]]
        k = 1
        while k < len(path):
            if path[k] == trimmed[-1]:
                # loop found
                k += 1
            trimmed.append(path[k])
            while len(trimmed) > 2 and trimmed[-1] == trimmed[-3]:
                # backtracking found
                del trimmed[-1]
                del trimmed[-1]
            k += 1
        return trimmed


def CGL_cycle(j0, ell):
    """ Compute a cycle in G(p,ell) at j0.

    When j0 is in Fp, this cycle may be trivial.
    """
    Fp_2 = j0.parent()
    Fp = Fp_2.base_ring()
    p = Fp.characteristic()
    P1 = random_walks_to_Fp(j0, ell)
    P1 = trim(P1)
    P1_conjugate = [j**p for j in P1]
    P1_conjugate.reverse()
    half_cycle_1 = P1 + P1_conjugate[1:]
    P2 = random_walks_to_Fp(j0, ell)
    while P2[-1] == P1[-1]:
        P2 = random_walks_to_Fp(j0, ell)
    P2 = trim(P2)
    P2_conjugate = [j**p for j in P2]
    P2.reverse()
    half_cycle_2 = P2_conjugate[1:] + P2[1:]
    return half_cycle_1 + half_cycle_2



def path_to_chain(path, ell):
    """ Given path a list of adjacent j-invariants in G(p,ell), return a corresponding isogeny chain.
    """

    jk = path[0]
    Ek = EllipticCurve(j=jk)
    chain = []
    for k in range(1, len(path)):
        neighbors = find_neighbors(Ek, ell)
        chain.append(neighbors[path[k]][0])
        Ek = chain[k - 1].codomain()
    # recompute last isogeny so that its codomain is E0
    f = chain[-1].kernel_polynomial()
    phi = EllipticCurveIsogeny(chain[-1].domain(), f, chain[0].domain())
    chain[-1] = phi
    return chain

def find_supersingular_j(p):
    """ Returns a supersingular j-invariant in Fp using Broker's algorithm."""
    F = GF(p^2)
    if not p.is_prime():
        raise ValueError('input must be prime')
    elif p%12 == 7:
        E = EllipticCurve([F(1),F(0)])
        j = E.j_invariant()
        epsilon = 1
    elif p%12 == 5:
        E = EllipticCurve([F(0),F(1)])
        j = E.j_invariant()
        epsilon = 1
    elif p%12 == 11:
        E = EllipticCurve([F(0),F(1)])
        j = E.j_invariant()
        epsilon = 2
    else:
        q = 3
        while kronecker(-q,p) == 1 or q%4 == 1:
            q = next_prime(q)
        PK = hilbert_class_polynomial(-q)
        Fx = F['x']
        PK = Fx(PK)
        j = PK.roots()[0][0]
        E = EllipticCurve(j=j)
        epsilon = 0
    return j



def suborder_experiment(p, ell, ntrials):
    """ For ntrials many iterations, compute a random supersingular j-invariant j in characteristic p, compute two cycles through j in the ell-isogeny graph, and test if they generate a Bass order. """

    j0 = find_supersingular_j(p)
    Fp_2 = j0.parent()
    Fp = Fp_2.base_ring()
    z2 = Fp_2.gen()
    z2_min_poly = z2.minimal_polynomial()
    data = {}
    data['bass'] = []
    data['fund_discs_gcd'] = []
    data['order_disc'] = []
    with open(f'{p}_inputs', 'a') as cycle_file:
        cycle_file.write(f'{p}, {z2_min_poly}\n')
    for _ in range(ntrials):
        j = random_walk(j0, ell)[-1]
        # CGL_cycle, as implemented, may compute trivial cycles if j is in Fp
        while j in Fp:
            j = random_walk(j0, ell)[-1]
        cycle1 = CGL_cycle(j,ell)
        cycle2 = CGL_cycle(j,ell)
        endo1 = path_to_chain(cycle1, ell)
        endo2 = path_to_chain(cycle2, ell)
        with open(f'{p}_inputs', 'a') as cycle_file:
            sendo1 = str([[[phi.domain().a4(), phi.domain().a6()], phi.kernel_polynomial()] for phi in endo1])
            sendo2 = str([[[phi.domain().a4(), phi.domain().a6()], phi.kernel_polynomial()] for phi in endo2])
            cycle_file.write(sendo1 + '\n')
            cycle_file.write(sendo2 + '\n')
        endo3 = endo1 + endo2
        t1 = generalized_Schoof(endo1)
        t2 = generalized_Schoof(endo2)
        t3 = generalized_Schoof(endo3)
        n1 = ell^(len(endo1))
        n2 = ell^(len(endo2))
        disc1 = t1^2 - 4 * n1
        disc2 = t2^2 - 4 * n2
        fund_disc1 = fundamental_discriminant(disc1)
        fund_disc2 = fundamental_discriminant(disc2)
        conductor_squared1 = disc1 / fund_disc1
        conductor_squared2 = disc2 / fund_disc2
        if fund_disc1 != fund_disc2:
            d = gcd(conductor_squared1, conductor_squared2)
            data['fund_discs_gcd'].append(d)
            bass = d == 1
            bass_except_ell = (bass) or (gcd(d, ell) == ell)
            data['bass'].append([bass, bass_except_ell])
        else:
            # endo1 and endo2 commute so they don't generate an order
            d = gcd(conductor_squared1, conductor_squared2)
            bass = False
            bass_except_ell = False
            data['bass'].append([bass, bass_except_ell])
            data['fund_discs_gcd'].append(d)
        G = matrix(4,
          [2, t1, t2, t3,
          t1, 2*n1, t1*t2-t3, t2*n1,
          t2, t1*t2-t3, 2*n2, n2*t1,
          t3, t2*n1, t1*n2, 2*n1*n2]);
        order_disc = G.det().sqrt()
        data['order_disc'].append(order_disc)
        with open(f'{p}_order_data', 'a') as order_file:
            sdata = str([bass, bass_except_ell, order_disc])
            order_file.write(sdata + '\n')
    return data

def suborder_data_analysis(f, p):
    """ Returns data in Figure 1 of the paper for entry p. Shows total number of orders, Bass orders, and the average number of maximal orders."""
    Omegas = []
    total_orders = 0
    total_bass = 0
    with open(f, 'r') as order_data:
        for line in order_data:
            data = eval(line)
            if data[2]:
                # disc != 0 so it is an order
                total_orders += 1
                if data[0]:
                    # it is a Bass order
                    total_bass += 1
                    disc = ZZ(data[2])
                    facts = disc.factor()
                    val_prod = 1
                    for fact in facts:
                        if fact[0] != p:
                            val_prod = val_prod * (fact[1] + 1)
                    Omegas.append(val_prod)
    return total_orders, total_bass, float(mean(Omegas))

def count_max_orders(f, p):
    """ Returns upper bound for number of max orders containing each bass order

    f: the file '{p}_order_data'
    p: prime
    """
    Omegas = []
    with open(f, 'r') as order_data:
        for line in order_data:
            data = eval(line)
            if data[0]:
                disc = ZZ(data[2])
                facts = disc.factor()
                val_prod = 1
                for fact in facts:
                    if fact[0] != p:
                        val_prod = val_prod * (fact[1] + 1)
                Omegas.append(val_prod)
    return Omegas
# def evaluate_char_poly(phi, P, t):
#     phiP = evaluate_chain(phi, P)
#     phiphiP = evaluate_chain(phi, phiP)
#     return phiphiP - t * phiP + ell^len(phi) * P

primes = [1009, 2003, 3001, 10007, 20011, 30011, 50021, 70001, 90001, 100003];
for i, f in enumerate([f'{p}_order_data' for p in primes]):
    p = primes[i]
    print(suborder_data_analysis(f, p))

x = count_max_orders('100003_order_data', 100003)
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline
plt.hist(x, bins=10)
plt.ylabel('N(O)');
plt.savefig('100003_max_order_count_10_bins')
